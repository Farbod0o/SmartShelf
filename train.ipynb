{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:27:14.667112Z",
     "start_time": "2024-11-11T11:27:05.747217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "id": "c7fc33336d014772",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:27:18.152496Z",
     "start_time": "2024-11-11T11:27:18.139227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv_image], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    "    return rotated_image\n",
    "\n",
    "def remove_background(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(gray_image, 30, 255, cv2.THRESH_BINARY)\n",
    "    foreground = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return foreground\n",
    "\n",
    "def preprocess_image(image):\n",
    "    foreground = remove_background(image)\n",
    "    gray_image = cv2.cvtColor(foreground, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    resized_image = cv2.resize(blurred_image, (128, 128))\n",
    "    return resized_image\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog_features = hog.compute(image).flatten()\n",
    "    return hog_features\n",
    "\n",
    "def extract_lbp_features(image, P=8, R=1):\n",
    "    lbp = np.zeros_like(image)\n",
    "    for i in range(R, image.shape[0] - R):\n",
    "        for j in range(R, image.shape[1] - R):\n",
    "            center = image[i, j]\n",
    "            binary_string = ''.join(['1' if image[i + dx, j + dy] >= center else '0'\n",
    "                                     for dx, dy in [(-1, -1), (-1, 0), (-1, 1), (0, 1),\n",
    "                                                    (1, 1), (1, 0), (1, -1), (0, -1)]])\n",
    "            lbp[i, j] = int(binary_string, 2)\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 2 ** P), range=(0, 2 ** P))\n",
    "    lbp_hist = lbp_hist / np.sum(lbp_hist)\n",
    "    return lbp_hist\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    classes = os.listdir(folder)\n",
    "    for class_name in classes:\n",
    "        class_folder = os.path.join(folder, class_name)\n",
    "        if not os.path.isdir(class_folder):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder):\n",
    "            file_path = os.path.join(class_folder, filename)\n",
    "            image = cv2.imread(file_path)\n",
    "            if image is not None:\n",
    "                preprocessed_image = preprocess_image(image)\n",
    "                angles = [0,30,45,60,90,120,180]\n",
    "                for angle in angles:\n",
    "                    rotated_image = rotate_image(preprocessed_image, angle)\n",
    "                    hog_features = extract_hog_features(rotated_image)\n",
    "                    lbp_features = extract_lbp_features(rotated_image)\n",
    "                    color_histogram = extract_color_histogram(image)\n",
    "                    combined_features = np.concatenate((hog_features, lbp_features,color_histogram))\n",
    "                    X.append(combined_features)\n",
    "                    y.append(class_name)\n",
    "    return np.array(X), np.array(y)\n"
   ],
   "id": "bc99f1e5c4fce612",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:27:19.269883Z",
     "start_time": "2024-11-11T11:27:19.260718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def scale_image(image, scale):\n",
    "    (h, w) = image.shape[:2]\n",
    "    new_size = (int(w * scale), int(h * scale))\n",
    "    resized = cv2.resize(image, new_size)\n",
    "    return resized\n",
    "\n",
    "def translate_image(image, x_shift, y_shift):\n",
    "    translation_matrix = np.float32([[1, 0, x_shift], [0, 1, y_shift]])\n",
    "    shifted = cv2.warpAffine(image, translation_matrix, (image.shape[1], image.shape[0]))\n",
    "    return shifted\n",
    "\n",
    "def adjust_brightness(image, factor):\n",
    "    adjusted = cv2.convertScaleAbs(image, alpha=factor, beta=0)\n",
    "    return adjusted\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, sigma=25):\n",
    "    gauss = np.random.normal(mean, sigma, image.shape).astype('uint8')\n",
    "    noisy = cv2.add(image, gauss)\n",
    "    return noisy"
   ],
   "id": "fceec657ccdd1e67",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:27:21.502357Z",
     "start_time": "2024-11-11T11:27:21.491156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "    angles = [-15, 15, -30, 30]\n",
    "    for angle in angles:\n",
    "        augmented_images.append(rotate_image(image, angle))\n",
    "\n",
    "    scales = [0.9, 1.1]\n",
    "    for scale in scales:\n",
    "        augmented_images.append(scale_image(image, scale))\n",
    "    shifts = [(10, 10), (-10, -10)]\n",
    "    for (x_shift, y_shift) in shifts:\n",
    "        augmented_images.append(translate_image(image, x_shift, y_shift))\n",
    "\n",
    "    brightness_factors = [0.7, 1.3]\n",
    "    for factor in brightness_factors:\n",
    "        augmented_images.append(adjust_brightness(image, factor))\n",
    "\n",
    "    augmented_images.append(add_gaussian_noise(image))\n",
    "    \n",
    "    return augmented_images"
   ],
   "id": "c1ebb77e002b389f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:14:27.682877Z",
     "start_time": "2024-11-11T12:11:01.671716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features_from_image(image):\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    hog_features = extract_hog_features(preprocessed_image)\n",
    "    lbp_features = extract_lbp_features(preprocessed_image)\n",
    "    color_histogram = extract_color_histogram(image)\n",
    "    combined_features = np.concatenate((hog_features, lbp_features, color_histogram))\n",
    "    return combined_features\n",
    "\n",
    "def load_images_with_features(folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_labels = os.listdir(folder)\n",
    "    label_map = {label: idx for idx, label in enumerate(class_labels)}\n",
    "    for label in class_labels:\n",
    "        class_folder = os.path.join(folder, label)\n",
    "        for filename in os.listdir(class_folder):\n",
    "            file_path = os.path.join(class_folder, filename)\n",
    "            image = cv2.imread(file_path)\n",
    "            features = extract_features_from_image(image)\n",
    "            X.append(features)\n",
    "            y.append(label_map[label])\n",
    "            augmented_images = augment_image(image)\n",
    "            for aug_image in augmented_images:\n",
    "                X.append(extract_features_from_image(aug_image))\n",
    "                y.append(label_map[label])\n",
    "    return np.array(X), np.array(y), label_map\n",
    "\n",
    "X, y, label_map = load_images_with_features('folder')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128,64), max_iter=500, alpha=0.001,solver='adam', random_state=42, verbose=True)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "X_train_mlp = mlp.predict_proba(X_train)\n",
    "X_test_mlp = mlp.predict_proba(X_test)"
   ],
   "id": "3f2c099d4c08a323",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.82380029\n",
      "Iteration 2, loss = 2.88595537\n",
      "Iteration 3, loss = 2.04470340\n",
      "Iteration 4, loss = 1.56322986\n",
      "Iteration 5, loss = 1.35263438\n",
      "Iteration 6, loss = 1.59158518\n",
      "Iteration 7, loss = 1.22126009\n",
      "Iteration 8, loss = 1.04892752\n",
      "Iteration 9, loss = 0.96373044\n",
      "Iteration 10, loss = 0.99363354\n",
      "Iteration 11, loss = 0.74983254\n",
      "Iteration 12, loss = 0.75863707\n",
      "Iteration 13, loss = 0.56544571\n",
      "Iteration 14, loss = 0.57398732\n",
      "Iteration 15, loss = 0.49360526\n",
      "Iteration 16, loss = 0.62010791\n",
      "Iteration 17, loss = 0.41860953\n",
      "Iteration 18, loss = 0.48735377\n",
      "Iteration 19, loss = 0.29190794\n",
      "Iteration 20, loss = 0.27705594\n",
      "Iteration 21, loss = 0.28455055\n",
      "Iteration 22, loss = 0.22262526\n",
      "Iteration 23, loss = 0.27722383\n",
      "Iteration 24, loss = 0.19057339\n",
      "Iteration 25, loss = 0.21243932\n",
      "Iteration 26, loss = 0.18690710\n",
      "Iteration 27, loss = 0.15132028\n",
      "Iteration 28, loss = 0.21679592\n",
      "Iteration 29, loss = 0.15031708\n",
      "Iteration 30, loss = 0.16012621\n",
      "Iteration 31, loss = 0.12714367\n",
      "Iteration 32, loss = 0.11570249\n",
      "Iteration 33, loss = 0.11295005\n",
      "Iteration 34, loss = 0.10561456\n",
      "Iteration 35, loss = 0.12792250\n",
      "Iteration 36, loss = 0.08331217\n",
      "Iteration 37, loss = 0.10404597\n",
      "Iteration 38, loss = 0.09291780\n",
      "Iteration 39, loss = 0.07748088\n",
      "Iteration 40, loss = 0.07960510\n",
      "Iteration 41, loss = 0.06456555\n",
      "Iteration 42, loss = 0.07247071\n",
      "Iteration 43, loss = 0.06173065\n",
      "Iteration 44, loss = 0.05516375\n",
      "Iteration 45, loss = 0.05820315\n",
      "Iteration 46, loss = 0.05003997\n",
      "Iteration 47, loss = 0.04826101\n",
      "Iteration 48, loss = 0.04419577\n",
      "Iteration 49, loss = 0.04725841\n",
      "Iteration 50, loss = 0.03912919\n",
      "Iteration 51, loss = 0.03898601\n",
      "Iteration 52, loss = 0.03756842\n",
      "Iteration 53, loss = 0.04254524\n",
      "Iteration 54, loss = 0.03211339\n",
      "Iteration 55, loss = 0.04255486\n",
      "Iteration 56, loss = 0.03376628\n",
      "Iteration 57, loss = 0.03039669\n",
      "Iteration 58, loss = 0.02911789\n",
      "Iteration 59, loss = 0.02825066\n",
      "Iteration 60, loss = 0.02969436\n",
      "Iteration 61, loss = 0.02496594\n",
      "Iteration 62, loss = 0.02469470\n",
      "Iteration 63, loss = 0.02695038\n",
      "Iteration 64, loss = 0.02389274\n",
      "Iteration 65, loss = 0.02394971\n",
      "Iteration 66, loss = 0.02336988\n",
      "Iteration 67, loss = 0.02242254\n",
      "Iteration 68, loss = 0.02990405\n",
      "Iteration 69, loss = 0.02139113\n",
      "Iteration 70, loss = 0.02570819\n",
      "Iteration 71, loss = 0.01938234\n",
      "Iteration 72, loss = 0.02364839\n",
      "Iteration 73, loss = 0.02038667\n",
      "Iteration 74, loss = 0.01732670\n",
      "Iteration 75, loss = 0.01955475\n",
      "Iteration 76, loss = 0.01940428\n",
      "Iteration 77, loss = 0.01613845\n",
      "Iteration 78, loss = 0.01618826\n",
      "Iteration 79, loss = 0.01721558\n",
      "Iteration 80, loss = 0.01566039\n",
      "Iteration 81, loss = 0.01511883\n",
      "Iteration 82, loss = 0.01595860\n",
      "Iteration 83, loss = 0.01525406\n",
      "Iteration 84, loss = 0.01426626\n",
      "Iteration 85, loss = 0.01375123\n",
      "Iteration 86, loss = 0.01353839\n",
      "Iteration 87, loss = 0.01293890\n",
      "Iteration 88, loss = 0.01258175\n",
      "Iteration 89, loss = 0.01270300\n",
      "Iteration 90, loss = 0.01254418\n",
      "Iteration 91, loss = 0.01207277\n",
      "Iteration 92, loss = 0.01174574\n",
      "Iteration 93, loss = 0.01154856\n",
      "Iteration 94, loss = 0.01140927\n",
      "Iteration 95, loss = 0.01116699\n",
      "Iteration 96, loss = 0.01105390\n",
      "Iteration 97, loss = 0.01100324\n",
      "Iteration 98, loss = 0.01084645\n",
      "Iteration 99, loss = 0.01054344\n",
      "Iteration 100, loss = 0.01039265\n",
      "Iteration 101, loss = 0.01049182\n",
      "Iteration 102, loss = 0.01019180\n",
      "Iteration 103, loss = 0.00989279\n",
      "Iteration 104, loss = 0.01035696\n",
      "Iteration 105, loss = 0.01037519\n",
      "Iteration 106, loss = 0.00969159\n",
      "Iteration 107, loss = 0.00980440\n",
      "Iteration 108, loss = 0.00974990\n",
      "Iteration 109, loss = 0.00933242\n",
      "Iteration 110, loss = 0.00924862\n",
      "Iteration 111, loss = 0.00936241\n",
      "Iteration 112, loss = 0.00907181\n",
      "Iteration 113, loss = 0.00884676\n",
      "Iteration 114, loss = 0.00876001\n",
      "Iteration 115, loss = 0.00872958\n",
      "Iteration 116, loss = 0.00863543\n",
      "Iteration 117, loss = 0.00844992\n",
      "Iteration 118, loss = 0.00827829\n",
      "Iteration 119, loss = 0.00814364\n",
      "Iteration 120, loss = 0.00809019\n",
      "Iteration 121, loss = 0.00813180\n",
      "Iteration 122, loss = 0.00811986\n",
      "Iteration 123, loss = 0.00793863\n",
      "Iteration 124, loss = 0.00797154\n",
      "Iteration 125, loss = 0.00764227\n",
      "Iteration 126, loss = 0.00756016\n",
      "Iteration 127, loss = 0.00745770\n",
      "Iteration 128, loss = 0.00739112\n",
      "Iteration 129, loss = 0.00728618\n",
      "Iteration 130, loss = 0.00716736\n",
      "Iteration 131, loss = 0.00705571\n",
      "Iteration 132, loss = 0.00697154\n",
      "Iteration 133, loss = 0.00685742\n",
      "Iteration 134, loss = 0.00676850\n",
      "Iteration 135, loss = 0.00663868\n",
      "Iteration 136, loss = 0.00655670\n",
      "Iteration 137, loss = 0.00645916\n",
      "Iteration 138, loss = 0.00638613\n",
      "Iteration 139, loss = 0.00628771\n",
      "Iteration 140, loss = 0.00616335\n",
      "Iteration 141, loss = 0.00608965\n",
      "Iteration 142, loss = 0.00599874\n",
      "Iteration 143, loss = 0.00613038\n",
      "Iteration 144, loss = 0.00589855\n",
      "Iteration 145, loss = 0.00569801\n",
      "Iteration 146, loss = 0.00557342\n",
      "Iteration 147, loss = 0.00562226\n",
      "Iteration 148, loss = 0.00545852\n",
      "Iteration 149, loss = 0.00539930\n",
      "Iteration 150, loss = 0.00549416\n",
      "Iteration 151, loss = 0.00523944\n",
      "Iteration 152, loss = 0.00555618\n",
      "Iteration 153, loss = 0.00509896\n",
      "Iteration 154, loss = 0.00515836\n",
      "Iteration 155, loss = 0.00501535\n",
      "Iteration 156, loss = 0.00514002\n",
      "Iteration 157, loss = 0.00497544\n",
      "Iteration 158, loss = 0.00554032\n",
      "Iteration 159, loss = 0.00485059\n",
      "Iteration 160, loss = 0.00480182\n",
      "Iteration 161, loss = 0.00483314\n",
      "Iteration 162, loss = 0.00471454\n",
      "Iteration 163, loss = 0.00473040\n",
      "Iteration 164, loss = 0.00473512\n",
      "Iteration 165, loss = 0.00458125\n",
      "Iteration 166, loss = 0.00466108\n",
      "Iteration 167, loss = 0.00454915\n",
      "Iteration 168, loss = 0.00482784\n",
      "Iteration 169, loss = 0.00443260\n",
      "Iteration 170, loss = 0.00458348\n",
      "Iteration 171, loss = 0.00437886\n",
      "Iteration 172, loss = 0.00449146\n",
      "Iteration 173, loss = 0.00437582\n",
      "Iteration 174, loss = 0.00436663\n",
      "Iteration 175, loss = 0.00435580\n",
      "Iteration 176, loss = 0.00428311\n",
      "Iteration 177, loss = 0.00434477\n",
      "Iteration 178, loss = 0.00422107\n",
      "Iteration 179, loss = 0.00420643\n",
      "Iteration 180, loss = 0.00418669\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Notebook\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model Accuracy: 94.64%\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:15:34.309899Z",
     "start_time": "2024-11-11T12:15:34.288892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "estimator = DecisionTreeClassifier(max_depth=5)\n",
    "ada_boost = AdaBoostClassifier(estimator=estimator, n_estimators=2, learning_rate=0.1, random_state=42)\n",
    "ada_boost.fit(X_train_mlp, y_train)\n",
    "\n",
    "y_pred = ada_boost.predict(X_test_mlp)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Combined Model Accuracy: {accuracy * 100:.2f}%\")"
   ],
   "id": "ab23b4ea0105aa39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model Accuracy: 94.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Notebook\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:40:40.983494Z",
     "start_time": "2024-11-11T12:31:49.823295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def predict_top_two_combined(frame, mlp_model, ada_model, label_map):\n",
    "    features = extract_features_from_image(frame)\n",
    "    mlp_probabilities = mlp_model.predict_proba([features])[0]\n",
    "    ada_probabilities = ada_model.predict_proba([mlp_probabilities])[0]\n",
    "    top_two_indices = np.argsort(ada_probabilities)[-2:][::-1]\n",
    "    top_two_classes = [(list(label_map.keys())[i], ada_probabilities[i]) for i in top_two_indices]\n",
    "    return top_two_classes\n",
    "\n",
    "def live_product_detection_combined(mlp_model, ada_model, label_map):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    last_time = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        height, width = frame.shape[:2]\n",
    "        box_size = 230\n",
    "        top_left_x = (width - box_size) // 2\n",
    "        top_left_y = (height - box_size) // 2\n",
    "        bottom_right_x = top_left_x + box_size\n",
    "        bottom_right_y = top_left_y + box_size\n",
    "        cv2.rectangle(frame, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), (0, 0, 255), 2)\n",
    "        cropped_frame = frame[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if current_time - last_time >= 2:\n",
    "            top_two_predictions = predict_top_two_combined(cropped_frame, mlp_model, ada_model, label_map)\n",
    "            last_time = current_time\n",
    "\n",
    "        for i, (class_name, probability) in enumerate(top_two_predictions):\n",
    "            if probability > 0.2:\n",
    "                text = f\"{class_name}: {probability * 100:.2f}%\"\n",
    "                cv2.putText(frame, text, (10, 30 + i * 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow(\"Live Product Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "live_product_detection_combined(mlp, ada_boost, label_map)\n"
   ],
   "id": "4ba52da101e4fb06",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:44:36.777124Z",
     "start_time": "2024-11-11T12:40:44.405690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_top_two(frame, model, label_map):\n",
    "    features = extract_features_from_image(frame)\n",
    "    probabilities = model.predict_proba([features])[0]\n",
    "    top_two_indices = np.argsort(probabilities)[-2:][::-1]\n",
    "    top_two_classes = [(list(label_map.keys())[i], probabilities[i]) for i in top_two_indices]\n",
    "    return top_two_classes\n",
    "\n",
    "def live_product_detection(model, label_map):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    last_time = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        height, width = frame.shape[:2]\n",
    "        box_size = 230\n",
    "        top_left_x = (width - box_size) // 2\n",
    "        top_left_y = (height - box_size) // 2\n",
    "        bottom_right_x = top_left_x + box_size\n",
    "        bottom_right_y = top_left_y + box_size\n",
    "        cv2.rectangle(frame, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), (0, 0, 255), 2)\n",
    "        cropped_frame = frame[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        \n",
    "\n",
    "        current_time = time.time()\n",
    "        if current_time - last_time >= 2:\n",
    "            top_two_predictions = predict_top_two(cropped_frame, model, label_map)\n",
    "            last_time = current_time\n",
    "\n",
    "        for i, (class_name, probability) in enumerate(top_two_predictions):\n",
    "            if probability > 0.2:\n",
    "                text = f\"{class_name}: {probability * 100:.2f}%\"\n",
    "                cv2.putText(frame, text, (10, 30 + i * 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "        cv2.imshow(\"Live Product Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "live_product_detection(mlp, label_map)"
   ],
   "id": "d4f1552b44a9a8ca",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:31:07.408267Z",
     "start_time": "2024-11-11T12:31:07.398017Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5cc12d11263d31a3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b3b9eae257c3048"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
